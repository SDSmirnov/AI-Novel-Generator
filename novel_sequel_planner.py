import google.generativeai as genai
import json
import numpy as np
import os
import random
import re
import sys
import time
import argparse

from dataclasses import dataclass, asdict, field
from datetime import datetime
from typing import List, Tuple, Dict, Any

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò–ó –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ì–û –§–ê–ô–õ–ê ---
# (–ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ API –≤ —ç—Ç–æ–º —Å–∫—Ä–∏–ø—Ç–µ)

API_KEY = os.getenv('AI_API_KEY', '–í–ê–®_API_–ö–õ–Æ–ß')
MODEL_NAME = "gemini-2.5-pro"

# –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ç—ã –∏ –æ–≤–µ—Ä—Ä–∞–π–¥—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
DEFAULT_CONCEPTS = open('prompts/global_concepts.md', 'r').read() if os.path.isfile('prompts/global_concepts.md') else ""
CONCEPTS = open('concepts.txt', 'r').read() if os.path.isfile('concepts.txt') else DEFAULT_CONCEPTS

DEFAULT_OVERRIDE = open('prompts/global_override.md', 'r').read() if os.path.isfile('prompts/global_override.md') else ""
SYSTEM_OVERRIDE = open('override.txt', 'r').read() if os.path.isfile('override.txt') else DEFAULT_OVERRIDE

ANTI_PLEASING = open('prompts/global_anti_pleasing.md', 'r').read() if os.path.isfile('prompts/global_anti_pleasing.md') else ""
PLANNER_ROLE = "–¢–≤–æ—è —Ä–æ–ª—å: –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä-–ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–µ–π —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –∫–Ω–∏–≥–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."

SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
]

STATS = {}

# --- –ö–û–ù–ï–¶ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò ---

def load_prompt(name: str, **kwargs) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç."""
    try:
        template = open(f'prompts/{name}.md', 'r', encoding='utf-8').read()
    except FileNotFoundError:
        print(f"[!] –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –§–∞–π–ª –ø—Ä–æ–º–ø—Ç–∞ 'prompts/{name}.md' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        sys.exit(1)

    def evaluator(match):
        expression = match.group(1)
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º locals() –∏ globals() –¥–ª—è –±–æ–ª–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ eval
            return str(eval(expression, globals(), kwargs))
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç–µ '{name}': {expression} -> {e}")
            return f"{{EVAL_ERROR: {expression}}}"
    return re.sub(r"\{(.*?)\}", evaluator, template)

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ö–µ–º—ã –∏ JSON-–ø—Ä–∏–º–µ—Ä—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
PLAN_SCHEMA = json.loads(load_prompt('schema_plan'))
SCHEMA_ANALYSIS = json.loads(load_prompt('schema_analysis'))
JSON_OUT = """
{
    "chapters": [
        {
            "number": "1",
            "title": "–ì–ª–∞–≤–∞ 1",
            "scenes": [
                "2025-10-17 11:30. –í–∞—Å—è, –∏–∑–º–æ—Ç–∞–Ω–Ω—ã–π –ø–æ—Å–ª–µ –±–µ—Å—Å–æ–Ω–Ω–æ–π –Ω–æ—á–∏, —Å–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ –æ—Ç–º—ã—Ç—É—é –ø–∏–≤–æ–≤–∞—Ä–Ω—é. –¶–µ–ª—å ‚Äî —Å–≤–∞—Ä–∏—Ç—å –ø—Ä–æ—Å—Ç–æ–π –ª–∞–≥–µ—Ä, –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ –æ—Å–Ω–æ–≤–∞–º. –û–Ω –Ω–µ –∏—â–µ—Ç –ø—Ä–æ—Ä—ã–≤–∞, –∞ –ø—ã—Ç–∞–µ—Ç—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å —á–µ—Ä–µ–∑ —Ä—É—Ç–∏–Ω—É. –û–Ω –º–µ—Ç–æ–¥–∏—á–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —á–∏—Å—Ç–æ—Ç—É —á–∞–Ω–∞, –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–µ—à–∫–∏ —Å —Å–æ–ª–æ–¥–æ–º. –í—Ö–æ–¥–∏—Ç –ú–∞—Ç—Ä—ë–Ω–∞ —Å –ø–∏—Å—å–º–æ–º –æ—Ç –ü–∏–ª—Å–Ω–µ—Ä–∞. –ö–õ–Æ–ß–ï–í–û–ô –ú–û–ú–ï–ù–¢: –í–∞—Å—è —á–∏—Ç–∞–µ—Ç –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—É—é –∂–∞–ª–æ–±—É –Ω–∞ '–Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —É—Ä–æ–≤–µ–Ω—å –∫–∞—Ä–±–æ–Ω–∏–∑–∞—Ü–∏–∏'. –í–º–µ—Å—Ç–æ –≥–Ω–µ–≤–∞ –∏–ª–∏ —Å—Ç—Ä–∞—Ö–∞ –æ–Ω —É—Å–º–µ—Ö–∞–µ—Ç—Å—è. –ü–û–ö–ê–ó–ê–¢–¨: –≠—Ç–æ –Ω–∞—á–∞–ª–æ –Ω–æ–≤–æ–π, '—Ö–æ–ª–æ–¥–Ω–æ–π' –≤–æ–π–Ω—ã, –∫–æ—Ç–æ—Ä–∞—è –µ–≥–æ –Ω–µ –ø—É–≥–∞–µ—Ç, –∞ –∑–∞–±–∞–≤–ª—è–µ—Ç. –û–Ω –±–µ—Ä–µ—Ç –ø–µ—Ä–æ –∏ –ø–∏—à–µ—Ç –∏—Ä–æ–Ω–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç. –°—Ü–µ–Ω–∞ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —Ç–æ–º, –∫–∞–∫ –ú–∞—Ç—Ä—ë–Ω–∞ —É–Ω–æ—Å–∏—Ç –µ–≥–æ –æ—Ç–≤–µ—Ç, –∫–∞—á–∞—è –≥–æ–ª–æ–≤–æ–π, –Ω–æ —Å —Ç–µ–Ω—å—é —É–ª—ã–±–∫–∏. –í—Ä–µ–º—è: ~20 –º–∏–Ω—É—Ç.",
                ...
            ]
        },
        ....
    ]
}
"""

import re
import json
import logging

from typing import Any, Dict, Optional

def robust_json_parser(llm_response: str) -> Optional[Dict[str, Any]]:
    """
    Attempts to extract and parse a JSON object from a string that may contain
    markdown fences or other extraneous text.

    Args:
        llm_response: The string response from the LLM, expected to contain JSON.

    Returns:
        A dictionary if parsing is successful, otherwise None.
    """
    # 1. Look for JSON within markdown fences ` ``json ... ``` `
    llm_response = re.sub(r'\s+', ' ', llm_response)
    match = re.search(r"```(?:json)?\s*(\{.*?\}|\[.*?\])\s```", llm_response, re.DOTALL)
    if match:
        json_str = match.group(1)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            logging.warning(f"JSON in markdown failed to parse: {e}. Content: '{json_str[:100]}...'")
            # Fall through to other methods in case of malformed JSON in markdown

    try:
        return json.loads(llm_response)
    except json.JSONDecodeError as e:
        logging.warning(f"JSON in markdown failed to parse: {e}. Content: '{llm_response[:1000]}...'")
        # Fall through to other methods in case of malformed JSON in markdown


    # 2. If no markdown, try to find the first '{' and last '}'
    try:
        start_index = llm_response.find('{')
        end_index = llm_response.rfind('}')
        if start_index != -1 and end_index != -1 and start_index < end_index:
            potential_json = llm_response[start_index:end_index+1]
            return json.loads(potential_json)
    except json.JSONDecodeError:
        # Fall through if this substring is not valid JSON
        pass

    # 3. As a last resort, try parsing the whole string
    try:
        return json.loads(llm_response)
    except json.JSONDecodeError:
        pass

    logging.error(f"Could not parse JSON from LLM response after multiple attempts. Response: '{llm_response}'")
    return None

@dataclass
class Step:
    """
    –ö–ª–∞—Å—Å Step –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ novel_generator.py,
    –Ω—É–∂–µ–Ω –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è "–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö" —à–∞–≥–æ–≤.
    """
    name: str
    handler_name: str
    status: str = 'planned'


class SequelPlanner:
    """
    –≠—Ç–æ—Ç –∫–ª–∞—Å—Å –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É —Ñ–∞–π–ª–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è —Å–∏–∫–≤–µ–ª–∞.
    –û–Ω –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ö–Ω–∏–≥–∏ 1, –æ–±–Ω–æ–≤–ª—è–µ—Ç "–ë–∏–±–ª–∏—é –ú–∏—Ä–∞" –¥–ª—è –ö–Ω–∏–≥–∏ 2
    –∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –ø–ª–∞–Ω –≥–ª–∞–≤.
    """
    def __init__(self, api_key, previous_state):
        genai.configure(api_key=api_key)

        self.new_state = {}
        self.base_model = None
        self.world_model = None # –ú–æ–¥–µ–ª—å —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ö–Ω–∏–≥–∏ 1

        self._load_and_prepare_state(previous_state)
        self._initialize_models()

    def _load_and_prepare_state(self, previous_state):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è."""
        print("  > –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∫–Ω–∏–≥–∏...")

        # 1. –ü–µ—Ä–µ–Ω–æ—Å –°–æ—Å—Ç–æ—è–Ω–∏—è –ú–∏—Ä–∞ (–ö—Ä–∏—Ç–∏—á–Ω–æ)
        self.new_state['world_state'] = previous_state.get('world_state', {})
        print(f"  ‚úì –°–æ—Å—Ç–æ—è–Ω–∏–µ –º–∏—Ä–∞ (–ø–µ—Ä—Å–æ–Ω–∞–∂–∏, –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å) –Ω–∞ –∫–æ–Ω–µ—Ü –ö–Ω–∏–≥–∏ 1 –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ.")

        # 2. –ü–µ—Ä–µ–Ω–æ—Å "–ë–∏–±–ª–∏–∏ –ú–∏—Ä–∞" (–ë—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∞)
        self.new_state['world_bible'] = previous_state.get('world_bible', {})
        if not self.new_state['world_bible']:
            print("[!] –û–®–ò–ë–ö–ê: 'world_bible' –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –ø—É—Å—Ç–∞. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å —Å–∏–∫–≤–µ–ª.")
            sys.exit(1)
        print("  ‚úì '–ë–∏–±–ª–∏—è –ú–∏—Ä–∞' –ö–Ω–∏–≥–∏ 1 –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.")

        # 3. –ü–µ—Ä–µ–Ω–æ—Å Qdrant (–ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –ø–æ–≤—Ç–æ—Ä–æ–≤)
        self.new_state['qdrant_collection_name'] = previous_state.get('qdrant_collection_name')
        if not self.new_state['qdrant_collection_name']:
            print("[!] –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ Qdrant. –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è.")
            self.new_state['qdrant_collection_name'] = f"novel_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        else:
            print(f"  ‚úì –ö–æ–ª–ª–µ–∫—Ü–∏—è Qdrant '{self.new_state['qdrant_collection_name']}' –±—É–¥–µ—Ç –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞.")

        # 4. –ü–µ—Ä–µ–Ω–æ—Å –†–µ–∑—é–º–µ –ì–ª–∞–≤ (–ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        self.new_state['chapter_summaries'] = previous_state.get('chapter_summaries', [])
        print(f"  ‚úì {len(self.new_state['chapter_summaries'])} —Ä–µ–∑—é–º–µ –≥–ª–∞–≤ –∏–∑ –ö–Ω–∏–≥–∏ 1 –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã.")

        # 5. –û—á–∏—Å—Ç–∫–∞
        self.new_state['final_chapters_text'] = []
        self.new_state['transient_data'] = {}
        self.new_state['steps'] = [] # –ë—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã –≤ –∫–æ–Ω—Ü–µ

        print("  ‚úì –ë–∞–∑–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —Å–∏–∫–≤–µ–ª–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ.")

    def _initialize_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª–∏, –≤–∫–ª—é—á–∞—è 'world_model' —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ö–Ω–∏–≥–∏ 1."""
        planner_context = f"{SYSTEM_OVERRIDE}\n{PLANNER_ROLE}\n{CONCEPTS}\n{ANTI_PLEASING}"

        self.base_model = genai.GenerativeModel(
            model_name=MODEL_NAME,
            system_instruction=planner_context,
            safety_settings=SAFETY_SETTINGS,
        )

        # –°—Ä–∞–∑—É —Å–æ–∑–¥–∞–µ–º world_model —Å "–ë–∏–±–ª–∏–µ–π" –ö–Ω–∏–≥–∏ 1
        self._create_world_model()

    def _create_world_model(self):
        """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å —Å system instruction, —Å–æ–¥–µ—Ä–∂–∞—â–µ–π –≤—Å—é '–ë–∏–±–ª–∏—é –ú–∏—Ä–∞'."""
        world_context = load_prompt(
            'global_world_model',
            world_bible=self.new_state['world_bible'],
            ANTI_PLEASING=ANTI_PLEASING,
            OVERRIDE=SYSTEM_OVERRIDE,
            CONCEPTS=CONCEPTS
        )
        self.world_model = genai.GenerativeModel(
            model_name=MODEL_NAME,
            system_instruction=world_context,
            safety_settings=SAFETY_SETTINGS,
        )
        print("‚úì –°–æ–∑–¥–∞–Ω–∞ –º–æ–¥–µ–ª—å —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º '–ë–∏–±–ª–∏–∏ –ú–∏—Ä–∞' (–ö–Ω–∏–≥–∞ 1)")

    def _call_gemini(self, prompt_text, temperature=0.8, use_world_model=False, response_schema=None):
        """–ù–∞–¥–µ–∂–Ω—ã–π –≤—ã–∑–æ–≤ API."""
        print(f"  > –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Gemini (model: {'world' if use_world_model else 'base'})...")

        model = self.world_model if use_world_model and self.world_model else self.base_model

        try:
            config_args = {
                "temperature": temperature,
                "max_output_tokens": 100000,
            }
            if response_schema:
                config_args['response_mime_type'] = 'application/json'
                config_args['response_schema'] = response_schema

            generation_config = genai.types.GenerationConfig(**config_args)
            print(prompt_text)
            response = model.generate_content(
                prompt_text,
                generation_config=generation_config,
                safety_settings=SAFETY_SETTINGS
            )
            print(response.text)

            if response.usage_metadata:
                model_key = model.model_name
                if model_key not in STATS:
                    STATS[model_key] = {'input_tokens': 0, 'output_tokens': 0, 'calls': 0}
                STATS[model_key]['input_tokens'] += response.usage_metadata.prompt_token_count
                STATS[model_key]['output_tokens'] += response.usage_metadata.candidates_token_count
                STATS[model_key]['calls'] += 1
                print(f"   [INFO] –¢–æ–∫–µ–Ω—ã (–≤/–≤/–≤—Å–µ–≥–æ): {response.usage_metadata.prompt_token_count}/{response.usage_metadata.candidates_token_count}/{response.usage_metadata.total_token_count}")

            return response.text

        except Exception as e:
            print(f"   ! –û—à–∏–±–∫–∞ API: {e}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ 10 —Å–µ–∫...")
            time.sleep(10)
            return self._call_gemini(prompt_text, temperature, use_world_model, response_schema)

    def run(self, sequel_synopsis, num_chapters):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —à–∞–≥–∏ –ø–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é —Å–∏–∫–≤–µ–ª–∞."""
        wb = self.new_state['world_bible'] # —Å—Å—ã–ª–∫–∞ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞

        old_summaries = self.new_state['chapter_summaries'] # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–µ —Å–∞–º–º–∞—Ä–∏ –ö–Ω–∏–≥–∏ 1
        old_state = self.new_state['world_state'] # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Å—Ç–µ–π—Ç –ö–Ω–∏–≥–∏ 1

        # "–®–ê–ì 0": –ö–û–ú–ü–†–ï–°–°–ò–Ø –ö–û–ù–¢–ï–ö–°–¢–ê ---
        print("\n--- [–®–∞–≥ 0.1] –°–∂–∞—Ç–∏–µ —Ä–µ–∑—é–º–µ –ö–Ω–∏–≥–∏ 1 ---")
        prompt_0_1 = load_prompt('sequel_0_1_book_summary', chapter_summaries=json.dumps(old_summaries, ensure_ascii=False))
        global_summary = self._call_gemini(prompt_0_1, temperature=0.5, use_world_model=False)
        # –ó–∞–º–µ–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑ 25 —Ä–µ–∑—é–º–µ –û–î–ù–ò–ú —Å–∂–∞—Ç—ã–º —Ä–µ–∑—é–º–µ.
        self.new_state['chapter_summaries'] = [global_summary] + [f"\n–ö–û–ù–ï–¶ –ü–†–ï–î–´–î–£–©–ï–ô –ö–ù–ò–ì–ò: [LAST_CHAPTER]{old_summaries[-1]}[/LAST_CHAPTER]"]
        print("  ‚úì –†–µ–∑—é–º–µ –≥–ª–∞–≤ –ö–Ω–∏–≥–∏ 1 —Å–∂–∞—Ç–æ –≤ –µ–¥–∏–Ω—ã–π '–ì–ª–æ–±–∞–ª—å–Ω—ã–π –ö–æ–Ω—Ç–µ–∫—Å—Ç'.")

        print("\n--- [–®–∞–≥ 0.2] –û—á–∏—Å—Ç–∫–∞ (Pruning) –°–æ—Å—Ç–æ—è–Ω–∏—è –ú–∏—Ä–∞ ---")
        prompt_0_2 = load_prompt('sequel_0_2_prune_state', world_state_json=json.dumps(old_state, ensure_ascii=False))
        pruned_state_json = self._call_gemini(prompt_0_2, temperature=0.3, use_world_model=False)
        # –ó–∞–º–µ–Ω—è–µ–º –º–∞—Å—Å–∏–≤–Ω—ã–π world_state –Ω–∞ –µ–≥–æ "—á–∏—Å—Ç—É—é" –≤–µ—Ä—Å–∏—é

        self.new_state['world_state'] = robust_json_parser(pruned_state_json)
        print("  ‚úì '–°–æ—Å—Ç–æ—è–Ω–∏–µ –ú–∏—Ä–∞' –æ—á–∏—â–µ–Ω–æ –æ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ –Ω–µ–Ω—É–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")

        # --- –û–ë–ù–û–í–õ–ï–ù–ò–ï "–ë–ò–ë–õ–ò–ò –ú–ò–†–ê" –î–õ–Ø –°–ò–ö–í–ï–õ–ê ---
        print("\n--- [–®–∞–≥ 1.1] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ê–Ω–∞–ª–∏–∑–∞ ---")
        prompt_1_1 = load_prompt('sequel_1_1_update_analysis', world_bible=wb, synopsis=sequel_synopsis, NUM_CHAPTERS=num_chapters)
        wb['analysis'] = json.loads(self._call_gemini(prompt_1_1, temperature=0.8, use_world_model=True, response_schema=SCHEMA_ANALYSIS))
        print("  ‚úì –ê–Ω–∞–ª–∏–∑ —Å—é–∂–µ—Ç–∞ –ö–Ω–∏–≥–∏ 2 —Å–æ–∑–¥–∞–Ω.")

        print("\n--- [–®–∞–≥ 1.2] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ü–µ—Ä—Å–æ–Ω–∞–∂–µ–π ---")
        prompt_1_2 = load_prompt('sequel_1_2_update_characters', world_bible=wb, synopsis=sequel_synopsis, NUM_CHAPTERS=num_chapters)
        wb['characters'] = self._call_gemini(prompt_1_2, temperature=0.9, use_world_model=True)
        print("  ‚úì –ê–Ω–∫–µ—Ç—ã –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –æ–±–Ω–æ–≤–ª–µ–Ω—ã/–¥–æ–ø–æ–ª–Ω–µ–Ω—ã.")

        print("\n--- [–®–∞–≥ 1.3] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –°–µ—Ç—Ç–∏–Ω–≥–∞ ---")
        prompt_1_3 = load_prompt('sequel_1_3_update_setting', world_bible=wb, synopsis=sequel_synopsis)
        wb['setting'] = wb['setting'] + '\n' + self._call_gemini(prompt_1_3, temperature=0.7, use_world_model=True)
        print("  ‚úì –°–µ—Ç—Ç–∏–Ω–≥ –æ–±–Ω–æ–≤–ª–µ–Ω (–¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ –ª–æ–∫–∞—Ü–∏–∏/–∏–∑–º–µ–Ω–µ–Ω–∏—è).")

        print("\n--- [–®–∞–≥ 1.4] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –†–µ—á–µ–≤—ã—Ö –ü—Ä–æ—Ñ–∏–ª–µ–π ---")
        prompt_1_4 = load_prompt('sequel_1_4_update_voice_profiles', world_bible=wb)
        wb['voice_profiles'] = self._call_gemini(prompt_1_4, temperature=0.9, use_world_model=True)
        print("  ‚úì –†–µ—á–µ–≤—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã/–¥–æ–ø–æ–ª–Ω–µ–Ω—ã.")

        # –®–∞–≥–∏ 1.5 –∏ 1.6 (–°—Ç–∏–ª—å) –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º - —Å—Ç–∏–ª—å —Ü–∏–∫–ª–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –µ–¥–∏–Ω—ã–º.
        print("\n--- [–®–∞–≥–∏ 1.5, 1.6] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –°—Ç–∏–ª—è ---")
        print("  ‚úì –°—Ç–∏–ª—å –∫–Ω–∏–≥–∏ –∏ —Ç–æ–Ω –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∏–∑ –ö–Ω–∏–≥–∏ 1 —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Ü–∏–∫–ª–∞.")

        # --- –ì–ï–ù–ï–†–ê–¶–ò–Ø –ù–û–í–û–ì–û –ü–õ–ê–ù–ê (–ø–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–µ) ---

        # –ü–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –ø–ª–∞–Ω–∞ –Ω–∞–º –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã 'world_model' –∑–Ω–∞–ª–∞ –æ–±
        # –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–∞—Ö, —Å–µ—Ç—Ç–∏–Ω–≥–µ –∏ —Ç.–¥.
        print("\n--- [–®–∞–≥ 1.10*] –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –ú–æ–¥–µ–ª–∏ –ú–∏—Ä–∞ (—Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏) ---")
        self._create_world_model()

        print("\n--- [–®–∞–≥ 1.7] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ü–ª–∞–Ω–∞ –ì–ª–∞–≤ (–ö–Ω–∏–≥–∞ 2) ---")
        prompt_1_7 = load_prompt('prompt_1_7_plan', world_bible=wb, json_out=JSON_OUT, NUM_CHAPTERS=num_chapters)
        scene_plan = self._call_gemini(prompt_1_7, temperature=0.8, use_world_model=True, response_schema=PLAN_SCHEMA)
        wb['chapters'] = json.loads(scene_plan)['chapters']
        print(f"  ‚úì –ü–ª–∞–Ω –Ω–∞ {len(wb['chapters'])} –≥–ª–∞–≤ –¥–ª—è –ö–Ω–∏–≥–∏ 2 —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")

        print("\n--- [–®–∞–≥ 1.8] –ö—Ä–∏—Ç–∏–∫–∞ –ü–ª–∞–Ω–∞ ---")
        full_plot_json = json.dumps(wb['chapters'], indent=2, ensure_ascii=False)
        prompt_1_8 = load_prompt('prompt_1_8_critique_plan', world_bible=wb, full_plot_json=full_plot_json, NUM_CHAPTERS=num_chapters)
        plot_critique = self._call_gemini(prompt_1_8, temperature=0.6, use_world_model=True)
        print("  ‚úì –ö—Ä–∏—Ç–∏–∫–∞ –ø–ª–∞–Ω–∞ –ø–æ–ª—É—á–µ–Ω–∞.")

        print("\n--- [–®–∞–≥ 1.9] –ü—Ä–∞–≤–∫–∞ –ü–ª–∞–Ω–∞ ---")
        prompt_1_9 = load_prompt('prompt_1_9_refactor_plan', world_bible=wb, plot_critique=plot_critique, full_plot_json=full_plot_json)
        edited_scene_plan_json = self._call_gemini(prompt_1_9, temperature=0.7, use_world_model=True, response_schema=PLAN_SCHEMA)
        wb['chapters'] = json.loads(edited_scene_plan_json)['chapters']
        print("  ‚úì –ü–ª–∞–Ω –≥–ª–∞–≤ –ö–Ω–∏–≥–∏ 2 –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –∏ —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

        # --- –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï "–ó–ê–í–ï–†–®–ï–ù–ù–´–•" –®–ê–ì–û–í ---
        print("\n--- [–§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è] –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤ 'Foundation' ---")
        steps = [
            Step(name="1.1 –ê–Ω–∞–ª–∏–∑", handler_name="step_foundation_1_1_analysis", status='done'),
            Step(name="1.2 –ü–µ—Ä—Å–æ–Ω–∞–∂–∏", handler_name="step_foundation_1_2_characters", status='done'),
            Step(name="1.3 –ú–∏—Ä", handler_name="step_foundation_1_3_setting", status='done'),
            Step(name="1.4 –†–µ—á–µ–≤—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏", handler_name="step_foundation_1_4_voice_profiles", status='done'),
            Step(name="1.5 –°—Ç–∏–ª—å –∫–Ω–∏–≥–∏", handler_name="step_foundation_1_5_book_style", status='done'),
            Step(name="1.6 –°—Ç–∏–ª—å –∏ —Ç–æ–Ω", handler_name="step_foundation_1_6_style", status='done'),
            Step(name="1.7 –ü–ª–∞–Ω", handler_name="step_foundation_1_7_plan", status='done'),
            Step(name="1.8 –ö—Ä–∏—Ç–∏–∫–∞ –ø–ª–∞–Ω–∞", handler_name="step_foundation_1_8_critique_plan", status='done'),
            Step(name="1.9 –ü—Ä–∞–≤–∫–∞ –ø–ª–∞–Ω–∞", handler_name="step_foundation_1_9_refactor_plan", status='done'),
            Step(name="1.10 –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–∏—Ä–∞", handler_name="step_foundation_1_10_create_world_model", status='done'),
        ]
        self.new_state['steps'] = [asdict(s) for s in steps]
        print("  ‚úì –í—Å–µ —à–∞–≥–∏ 'Foundation' –æ—Ç–º–µ—á–µ–Ω—ã –∫–∞–∫ 'done'.")

        return self.new_state


if __name__ == "__main__":
    if API_KEY == '–í–ê–®_API_–ö–õ–Æ–ß':
        print("–û—à–∏–±–∫–∞: –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—Å—Ç–∞–≤—å—Ç–µ –≤–∞—à API –∫–ª—é—á –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é API_KEY.")
        sys.exit(1)

    parser = argparse.ArgumentParser(description="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–∫–≤–µ–ª–∞ —Ä–æ–º–∞–Ω–∞.")
    parser.add_argument("--input", required=True, help="–§–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∫–Ω–∏–≥–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, novel_project_state.json)")
    parser.add_argument("--output", required=True, help="–ò–º—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è —Å–∏–∫–≤–µ–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, sequel_project_state.json)")
    parser.add_argument("--synopsis", required=True, help="–¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å —Å–∏–Ω–æ–ø—Å–∏—Å–æ–º –¥–ª—è *–Ω–æ–≤–æ–π* –∫–Ω–∏–≥–∏ (—Å–∏–∫–≤–µ–ª–∞).")
    parser.add_argument("--chapters", type=int, default=4, help="–ñ–µ–ª–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∞–≤ –≤ —Å–∏–∫–≤–µ–ª–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 4).")

    args = parser.parse_args()

    # --- 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏–∑: {args.input}")
    try:
        with open(args.input, 'r', encoding='utf-8') as f:
            previous_state = json.load(f)
    except FileNotFoundError:
        print(f"[!] –û–®–ò–ë–ö–ê: –§–∞–π–ª '{args.input}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"[!] –û–®–ò–ë–ö–ê: –§–∞–π–ª '{args.input}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON.")
        sys.exit(1)

    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏–Ω–æ–ø—Å–∏—Å–∞ —Å–∏–∫–≤–µ–ª–∞ –∏–∑: {args.synopsis}")
    try:
        with open(args.synopsis, 'r', encoding='utf-8') as f:
            synopsis_text = f.read()
    except FileNotFoundError:
        print(f"[!] –û–®–ò–ë–ö–ê: –§–∞–π–ª —Å–∏–Ω–æ–ø—Å–∏—Å–∞ '{args.synopsis}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        sys.exit(1)

    # --- 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ ---
    print("–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ —Å–∏–∫–≤–µ–ª–∞...")
    try:
        planner = SequelPlanner(api_key=API_KEY, previous_state=previous_state)
        new_project_state = planner.run(sequel_synopsis=synopsis_text, num_chapters=args.chapters)

        # --- 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ---
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(new_project_state, f, indent=2, ensure_ascii=False)

        print(f"\nüéâ –£–°–ü–ï–•! –ù–æ–≤—ã–π —Ñ–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è '{args.output}' –≥–æ—Ç–æ–≤.")
        print("–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤–∞—à –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π 'novel_generator.py',")
        print(f"—É–∫–∞–∑–∞–≤ –µ–º—É —ç—Ç–æ—Ç —Ñ–∞–π–ª, —á—Ç–æ–±—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ö–Ω–∏–≥—É 2.")
        print(f"\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ (–≤—Å–µ–≥–æ): {STATS}")

    except Exception as e:
        print(f"\n[!] –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
